dataset:
  train_path: "data/SQuAD-PL/train.csv"
  test_path: "data/SQuAD-PL/test.csv"
  back_translate_paths:
  - "data/SQuAD-PL/train_en_de_pl.csv"
  - "data/SQuAD-PL/train_en_fi_pl.csv"
  - "data/SQuAD-PL/train_en_fr_pl.csv"
  - "data/SQuAD-PL/train_en_hi_pl.csv"
  - "data/SQuAD-PL/train_en_it_pl.csv"
  - "data/SQuAD-PL/train_en_ru_pl.csv"
  sample_size: 1000
  answer_only: false
model:
  path: "models/herbert-base-cased"
  max_length: 384
  stride: 128
train:
  seed: 42
  folds: 5
  fold: "all"
  epochs: 5
  batch_size: 4
  gradient_accumulation: 8
  eval_freq: 10
  lr: 2.0e-5
  weight_decay: 1.0e-2
  save_path: "experiments/squad-pl-1k/herbert-base-cased/baseline"
augmentation:
  enabled_train: false
  enabled_dev: false
  p_back_translate: 0
  p_prepend_context: 0
  p_append_context: 0
  p_replace_question: 0
  p_replace_question_entity: 0
  p_change_question_type: 0
  p_drop_answer: 0
  replace_dropped_answer_with_mask: false
  p_drop_token: 0
  replace_dropped_token_with_mask: false
  n_insert_token: 0
  p_replace_token_with_lemma: 0
  p_swap_token: 0
  p_drop_char: 0
  p_replace_polish_char: 0
  p_replace_uppercase_char: 0
