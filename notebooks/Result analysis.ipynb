{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e23b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c859ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-1k/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{prepend-append-context-0.4} & 0.545 & 0.523 & 0.271 & 0.227 & 0.819 & 0.819 \\\\\n",
      "\\texttt{prepend-append-context-0.25} & 0.544 & 0.523 & 0.272 & 0.231 & 0.816 & 0.816 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.543 & 0.520 & 0.281 & 0.235 & 0.805 & 0.805 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.543 & 0.529 & 0.201 & 0.171 & 0.886 & 0.886 \\\\\n",
      "\\texttt{prepend-append-context-0.8} & 0.543 & 0.521 & 0.272 & 0.229 & 0.814 & 0.814 \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.543 & 0.518 & 0.317 & 0.267 & 0.768 & 0.768 \\\\\n",
      "\\texttt{append-context-0.5} & 0.537 & 0.513 & 0.284 & 0.236 & 0.790 & 0.790 \\\\\n",
      "\\texttt{replace-polish-char-0.8} & 0.537 & 0.520 & 0.208 & 0.175 & 0.865 & 0.865 \\\\\n",
      "\\texttt{drop-char-0.01} & 0.536 & 0.519 & 0.222 & 0.188 & 0.851 & 0.851 \\\\\n",
      "\\texttt{back-translate-0.5} & 0.535 & 0.514 & 0.291 & 0.249 & 0.778 & 0.778 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.8} & 0.535 & 0.521 & 0.191 & 0.164 & 0.879 & 0.879 \\\\\n",
      "\\texttt{drop-token-0.01} & 0.535 & 0.517 & 0.232 & 0.196 & 0.838 & 0.838 \\\\\n",
      "\\texttt{back-translate-0.8} & 0.535 & 0.514 & 0.269 & 0.229 & 0.800 & 0.800 \\\\\n",
      "\\texttt{prepend-append-context-0.1} & 0.535 & 0.512 & 0.283 & 0.237 & 0.786 & 0.786 \\\\\n",
      "\\texttt{replace-polish-char-0.2} & 0.532 & 0.512 & 0.249 & 0.209 & 0.816 & 0.816 \\\\\n",
      "\\texttt{drop-char-0.001} & 0.532 & 0.515 & 0.236 & 0.201 & 0.828 & 0.828 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.5} & 0.532 & 0.517 & 0.206 & 0.177 & 0.857 & 0.857 \\\\\n",
      "\\texttt{prepend-context-0.2} & 0.531 & 0.508 & 0.281 & 0.236 & 0.781 & 0.781 \\\\\n",
      "\\texttt{replace-polish-char-0.5} & 0.530 & 0.508 & 0.272 & 0.229 & 0.787 & 0.787 \\\\\n",
      "\\texttt{replace-question-0.2} & 0.529 & 0.510 & 0.218 & 0.180 & 0.840 & 0.840 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.2} & 0.529 & 0.511 & 0.233 & 0.197 & 0.825 & 0.825 \\\\\n",
      "\\texttt{back-translate-0.2} & 0.529 & 0.508 & 0.258 & 0.216 & 0.800 & 0.800 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.529 & 0.514 & 0.188 & 0.158 & 0.869 & 0.869 \\\\\n",
      "\\texttt{replace-uppercase-char-0.2} & 0.528 & 0.509 & 0.253 & 0.214 & 0.803 & 0.803 \\\\\n",
      "\\texttt{insert-token-8} & 0.528 & 0.510 & 0.239 & 0.202 & 0.818 & 0.818 \\\\\n",
      "\\texttt{replace-question-0.5} & 0.528 & 0.513 & 0.188 & 0.159 & 0.868 & 0.868 \\\\\n",
      "\\texttt{prepend-context-0.5} & 0.528 & 0.501 & 0.309 & 0.255 & 0.746 & 0.746 \\\\\n",
      "\\texttt{append-context-0.8} & 0.527 & 0.510 & 0.215 & 0.180 & 0.839 & 0.839 \\\\\n",
      "\\texttt{replace-uppercase-char-0.8} & 0.526 & 0.511 & 0.229 & 0.198 & 0.823 & 0.823 \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.526 & 0.514 & 0.177 & 0.152 & 0.876 & 0.876 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.525 & 0.506 & 0.241 & 0.203 & 0.810 & 0.810 \\\\\n",
      "\\texttt{drop-token-mask-0.01} & 0.525 & 0.506 & 0.254 & 0.217 & 0.796 & 0.796 \\\\\n",
      "\\texttt{replace-uppercase-char-0.5} & 0.523 & 0.507 & 0.217 & 0.184 & 0.829 & 0.829 \\\\\n",
      "\\texttt{append-context-0.2} & 0.523 & 0.504 & 0.239 & 0.202 & 0.806 & 0.806 \\\\\n",
      "\\texttt{insert-token-2} & 0.522 & 0.502 & 0.256 & 0.215 & 0.788 & 0.788 \\\\\n",
      "\\texttt{drop-token-0.1} & 0.522 & 0.505 & 0.203 & 0.170 & 0.840 & 0.840 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.520} & \\textbf{0.499} & \\textbf{0.266} & \\textbf{0.225} & \\textbf{0.773} & \\textbf{0.773} \\\\\n",
      "\\texttt{change-question-type-0.5} & 0.519 & 0.512 & 0.101 & 0.086 & 0.938 & 0.938 \\\\\n",
      "\\texttt{insert-token-4} & 0.517 & 0.497 & 0.258 & 0.217 & 0.777 & 0.777 \\\\\n",
      "\\texttt{drop-answer-mask-0.2} & 0.514 & 0.505 & 0.131 & 0.113 & 0.897 & 0.897 \\\\\n",
      "\\texttt{drop-token-mask-0.1} & 0.514 & 0.498 & 0.197 & 0.165 & 0.831 & 0.831 \\\\\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.513 & 0.509 & 0.052 & 0.044 & 0.974 & 0.974 \\\\\n",
      "\\texttt{replace-question-entity-0.5} & 0.512 & 0.505 & 0.098 & 0.083 & 0.926 & 0.926 \\\\\n",
      "\\texttt{swap-token-0.5} & 0.508 & 0.497 & 0.144 & 0.122 & 0.872 & 0.872 \\\\\n",
      "\\texttt{swap-token-0.2} & 0.506 & 0.491 & 0.189 & 0.159 & 0.823 & 0.823 \\\\\n",
      "\\texttt{drop-answer-0.5} & 0.503 & 0.502 & 0.008 & 0.007 & 0.997 & 0.997 \\\\\n",
      "\\texttt{replace-question-0.8} & 0.501 & 0.500 & 0.008 & 0.007 & 0.993 & 0.993 \\\\\n",
      "\\texttt{change-question-type-0.8} & 0.500 & 0.500 & 0.001 & 0.001 & 0.999 & 0.999 \\\\\n",
      "\\texttt{drop-answer-0.8} & 0.500 & 0.500 & 0.000 & 0.000 & 1.000 & 1.000 \\\\\n",
      "\\texttt{drop-answer-mask-0.8} & 0.500 & 0.500 & 0.000 & 0.000 & 1.000 & 1.000 \\\\\n",
      "\\texttt{replace-question-entity-0.8} & 0.496 & 0.494 & 0.015 & 0.012 & 0.976 & 0.976 \\\\\n",
      "\\texttt{drop-answer-mask-0.5} & 0.491 & 0.485 & 0.057 & 0.046 & 0.925 & 0.925 \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-1k-answer-only/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{drop-answer-0.5} & 0.507 & 0.487 & 0.265 & 0.225 & 0.749 & 0.749 \\\\\n",
      "\\texttt{drop-answer-0.8} & 0.500 & 0.500 & 0.000 & 0.000 & 1.000 & 1.000 \\\\\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.465 & 0.433 & 0.346 & 0.282 & 0.584 & 0.584 \\\\\n",
      "\\texttt{change-question-type-0.8} & 0.415 & 0.404 & 0.153 & 0.130 & 0.678 & 0.678 \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.409 & 0.363 & 0.503 & 0.411 & 0.315 & 0.315 \\\\\n",
      "\\texttt{prepend-append-context-0.8} & 0.402 & 0.350 & 0.584 & 0.480 & 0.220 & 0.220 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.367 & 0.313 & 0.575 & 0.467 & 0.159 & 0.159 \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.362 & 0.309 & 0.587 & 0.480 & 0.137 & 0.137 \\\\\n",
      "\\texttt{replace-question-entity-0.5} & 0.362 & 0.319 & 0.428 & 0.342 & 0.295 & 0.295 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.360 & 0.309 & 0.510 & 0.408 & 0.210 & 0.210 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.359 & 0.311 & 0.507 & 0.411 & 0.212 & 0.212 \\\\\n",
      "\\texttt{prepend-append-context-0.25} & 0.359 & 0.304 & 0.587 & 0.478 & 0.131 & 0.131 \\\\\n",
      "\\texttt{prepend-append-context-0.4} & 0.357 & 0.305 & 0.584 & 0.479 & 0.131 & 0.131 \\\\\n",
      "\\texttt{replace-question-entity-0.8} & 0.357 & 0.323 & 0.326 & 0.259 & 0.388 & 0.388 \\\\\n",
      "\\texttt{insert-token-8} & 0.353 & 0.303 & 0.534 & 0.434 & 0.173 & 0.173 \\\\\n",
      "\\texttt{prepend-context-0.5} & 0.345 & 0.290 & 0.570 & 0.460 & 0.119 & 0.119 \\\\\n",
      "\\texttt{change-question-type-0.5} & 0.336 & 0.295 & 0.435 & 0.352 & 0.238 & 0.238 \\\\\n",
      "\\texttt{prepend-append-context-0.1} & 0.335 & 0.282 & 0.568 & 0.461 & 0.103 & 0.103 \\\\\n",
      "\\texttt{append-context-0.5} & 0.335 & 0.281 & 0.567 & 0.460 & 0.102 & 0.102 \\\\\n",
      "\\texttt{append-context-0.8} & 0.332 & 0.278 & 0.562 & 0.454 & 0.101 & 0.101 \\\\\n",
      "\\texttt{append-context-0.2} & 0.330 & 0.277 & 0.558 & 0.452 & 0.102 & 0.102 \\\\\n",
      "\\texttt{prepend-context-0.2} & 0.327 & 0.274 & 0.562 & 0.457 & 0.092 & 0.092 \\\\\n",
      "\\texttt{drop-answer-mask-0.2} & 0.325 & 0.274 & 0.513 & 0.412 & 0.137 & 0.137 \\\\\n",
      "\\texttt{drop-token-0.1} & 0.325 & 0.274 & 0.533 & 0.432 & 0.116 & 0.116 \\\\\n",
      "\\texttt{replace-question-0.2} & 0.321 & 0.266 & 0.543 & 0.433 & 0.100 & 0.100 \\\\\n",
      "\\texttt{replace-question-0.5} & 0.318 & 0.267 & 0.497 & 0.393 & 0.140 & 0.140 \\\\\n",
      "\\texttt{drop-token-0.01} & 0.311 & 0.260 & 0.550 & 0.447 & 0.072 & 0.072 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.2} & 0.309 & 0.257 & 0.554 & 0.451 & 0.063 & 0.063 \\\\\n",
      "\\texttt{drop-token-mask-0.01} & 0.308 & 0.257 & 0.553 & 0.450 & 0.064 & 0.064 \\\\\n",
      "\\texttt{drop-char-0.001} & 0.307 & 0.256 & 0.554 & 0.452 & 0.061 & 0.061 \\\\\n",
      "\\texttt{replace-uppercase-char-0.2} & 0.304 & 0.254 & 0.551 & 0.450 & 0.057 & 0.057 \\\\\n",
      "\\texttt{insert-token-2} & 0.304 & 0.252 & 0.547 & 0.443 & 0.062 & 0.062 \\\\\n",
      "\\texttt{insert-token-4} & 0.304 & 0.254 & 0.535 & 0.434 & 0.073 & 0.073 \\\\\n",
      "\\texttt{back-translate-0.5} & 0.301 & 0.247 & 0.564 & 0.456 & 0.037 & 0.037 \\\\\n",
      "\\texttt{drop-token-mask-0.1} & 0.298 & 0.245 & 0.512 & 0.407 & 0.084 & 0.084 \\\\\n",
      "\\texttt{drop-char-0.01} & 0.298 & 0.244 & 0.560 & 0.453 & 0.035 & 0.035 \\\\\n",
      "\\texttt{replace-polish-char-0.2} & 0.297 & 0.244 & 0.548 & 0.442 & 0.046 & 0.046 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.295 & 0.243 & 0.542 & 0.437 & 0.049 & 0.049 \\\\\n",
      "\\texttt{replace-uppercase-char-0.5} & 0.295 & 0.243 & 0.548 & 0.443 & 0.043 & 0.043 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.295} & \\textbf{0.243} & \\textbf{0.547} & \\textbf{0.442} & \\textbf{0.043} & \\textbf{0.043} \\\\\n",
      "\\texttt{back-translate-0.8} & 0.292 & 0.237 & 0.552 & 0.443 & 0.032 & 0.032 \\\\\n",
      "\\texttt{replace-polish-char-0.5} & 0.289 & 0.236 & 0.539 & 0.433 & 0.038 & 0.038 \\\\\n",
      "\\texttt{replace-uppercase-char-0.8} & 0.287 & 0.235 & 0.541 & 0.438 & 0.032 & 0.032 \\\\\n",
      "\\texttt{swap-token-0.2} & 0.286 & 0.234 & 0.541 & 0.438 & 0.031 & 0.031 \\\\\n",
      "\\texttt{back-translate-0.2} & 0.286 & 0.232 & 0.543 & 0.435 & 0.029 & 0.029 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.5} & 0.282 & 0.231 & 0.528 & 0.425 & 0.037 & 0.037 \\\\\n",
      "\\texttt{replace-polish-char-0.8} & 0.282 & 0.229 & 0.529 & 0.424 & 0.035 & 0.035 \\\\\n",
      "\\texttt{replace-question-0.8} & 0.273 & 0.223 & 0.404 & 0.304 & 0.142 & 0.142 \\\\\n",
      "\\texttt{replace-token-with-lemma-0.8} & 0.260 & 0.212 & 0.502 & 0.405 & 0.019 & 0.019 \\\\\n",
      "\\texttt{swap-token-0.5} & 0.244 & 0.196 & 0.481 & 0.384 & 0.008 & 0.008 \\\\\n",
      "\\texttt{drop-answer-mask-0.5} & 0.242 & 0.195 & 0.442 & 0.349 & 0.042 & 0.042 \\\\\n",
      "\\texttt{drop-answer-mask-0.8} & 0.137 & 0.107 & 0.254 & 0.194 & 0.020 & 0.020 \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-5k/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.619 & 0.590 & 0.485 & 0.426 & 0.754 & 0.754 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.615 & 0.590 & 0.439 & 0.390 & 0.791 & 0.791 \\\\\n",
      "\\texttt{append-context-0.5} & 0.609 & 0.587 & 0.416 & 0.371 & 0.803 & 0.803 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.608 & 0.580 & 0.457 & 0.401 & 0.759 & 0.759 \\\\\n",
      "\\texttt{back-translate-0.5} & 0.608 & 0.579 & 0.468 & 0.411 & 0.747 & 0.747 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.604 & 0.576 & 0.435 & 0.378 & 0.773 & 0.773 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.602 & 0.579 & 0.397 & 0.349 & 0.808 & 0.808 \\\\\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.602 & 0.579 & 0.358 & 0.313 & 0.845 & 0.845 \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.598 & 0.573 & 0.439 & 0.390 & 0.757 & 0.757 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.598} & \\textbf{0.569} & \\textbf{0.447} & \\textbf{0.390} & \\textbf{0.749} & \\textbf{0.749} \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-5k-answer-only/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.459 & 0.417 & 0.592 & 0.509 & 0.325 & 0.325 \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.432 & 0.385 & 0.634 & 0.541 & 0.230 & 0.230 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.418 & 0.371 & 0.637 & 0.542 & 0.200 & 0.200 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.397 & 0.348 & 0.663 & 0.565 & 0.130 & 0.130 \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.395 & 0.345 & 0.673 & 0.571 & 0.118 & 0.118 \\\\\n",
      "\\texttt{append-context-0.5} & 0.378 & 0.330 & 0.653 & 0.558 & 0.103 & 0.103 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.371 & 0.321 & 0.649 & 0.548 & 0.093 & 0.093 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.361 & 0.312 & 0.657 & 0.560 & 0.065 & 0.065 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.352} & \\textbf{0.302} & \\textbf{0.662} & \\textbf{0.561} & \\textbf{0.043} & \\textbf{0.043} \\\\\n",
      "\\texttt{back-translate-0.5} & 0.348 & 0.299 & 0.659 & 0.561 & 0.038 & 0.038 \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-10k/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{back-translate-0.5} & 0.651 & 0.621 & 0.516 & 0.456 & 0.787 & 0.787 \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.651 & 0.623 & 0.490 & 0.434 & 0.811 & 0.811 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.643 & 0.617 & 0.461 & 0.408 & 0.825 & 0.825 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.642 & 0.616 & 0.463 & 0.412 & 0.820 & 0.820 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.640 & 0.616 & 0.467 & 0.419 & 0.813 & 0.813 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.638 & 0.606 & 0.545 & 0.481 & 0.731 & 0.731 \\\\\n",
      "\\texttt{append-context-0.5} & 0.634 & 0.601 & 0.522 & 0.456 & 0.745 & 0.745 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.629} & \\textbf{0.597} & \\textbf{0.520} & \\textbf{0.455} & \\textbf{0.738} & \\textbf{0.738} \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.623 & 0.595 & 0.498 & 0.443 & 0.748 & 0.748 \\\\\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.609 & 0.593 & 0.357 & 0.324 & 0.861 & 0.861 \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-10k-answer-only/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\texttt{replace-question-0.2-replace-question-entity-0.2-change-question-type-0.2-drop-answer-0.2} & 0.452 & 0.404 & 0.642 & 0.545 & 0.263 & 0.263 \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.401 & 0.354 & 0.695 & 0.601 & 0.108 & 0.108 \\\\\n",
      "\\texttt{prepend-context-0.8} & 0.400 & 0.348 & 0.694 & 0.590 & 0.105 & 0.105 \\\\\n",
      "\\texttt{append-context-0.5} & 0.397 & 0.348 & 0.674 & 0.576 & 0.119 & 0.119 \\\\\n",
      "\\texttt{replace-question-entity-0.2} & 0.394 & 0.345 & 0.664 & 0.565 & 0.124 & 0.124 \\\\\n",
      "\\texttt{drop-token-0.01-replace-token-with-lemma-0.1-swap-token-0.01-drop-char-0.001-replace-polish-char-0.5-replace-uppercase-char-0.5} & 0.394 & 0.347 & 0.685 & 0.590 & 0.103 & 0.103 \\\\\n",
      "\\texttt{change-question-type-0.2} & 0.383 & 0.333 & 0.664 & 0.564 & 0.103 & 0.103 \\\\\n",
      "\\texttt{drop-answer-0.2} & 0.380 & 0.330 & 0.658 & 0.556 & 0.103 & 0.103 \\\\\n",
      "\\texttt{back-translate-0.5} & 0.377 & 0.328 & 0.681 & 0.585 & 0.072 & 0.072 \\\\\n",
      "\\textbf{baseline} & \\textbf{0.363} & \\textbf{0.312} & \\textbf{0.683} & \\textbf{0.583} & \\textbf{0.042} & \\textbf{0.042} \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "../experiments/squad-pl-50k/herbert-base-cased\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\\begin{longtable}[H]{c|cc|cc|cc}\n",
      "\\caption*{Wyniki modeli trenowanych na zbiorze \\texttt{squad-pl-???} (uporządkowane wg F\\textsubscript{1}).} \\\\\n",
      "\\toprule\n",
      "\\multicolumn{1}{c|}{} & \\multicolumn{2}{c|}{} & \\multicolumn{2}{c|}{z odp.} & \\multicolumn{2}{c}{bez odp.} \\\\\n",
      "{augmentacja} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} & {F\\textsubscript{1}} & {EM} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "\\textbf{baseline} & \\textbf{0.704} & \\textbf{0.669} & \\textbf{0.604} & \\textbf{0.535} & \\textbf{0.804} & \\textbf{0.804} \\\\\n",
      "\\texttt{back-translate-0.5-prepend-0.5-append-0.5} & 0.697 & 0.659 & 0.625 & 0.550 & 0.769 & 0.769 \\\\\n",
      "\\bottomrule\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def render_table(data):\n",
    "    table = \"\"\n",
    "    table += \"\\\\begin{longtable}[H]{c|cc|cc|cc}\\n\"\n",
    "    table += \"\\\\caption*{Wyniki modeli trenowanych na zbiorze \\\\texttt{squad-pl-???} (uporządkowane wg F\\\\textsubscript{1}).} \\\\\\\\\\n\"\n",
    "    table += \"\\\\toprule\\n\"\n",
    "    table += \"\\\\multicolumn{1}{c|}{} & \\\\multicolumn{2}{c|}{} & \\\\multicolumn{2}{c|}{z odp.} & \\\\multicolumn{2}{c}{bez odp.} \\\\\\\\\\n\"\n",
    "    table += \"{augmentacja} & {F\\\\textsubscript{1}} & {EM} & {F\\\\textsubscript{1}} & {EM} & {F\\\\textsubscript{1}} & {EM} \\\\\\\\\\n\"\n",
    "    table += \"\\\\midrule\\n\"\n",
    "    table += \"\\\\midrule\\n\"\n",
    "    \n",
    "    data.sort(key=lambda x: x[1], reverse=True)\n",
    "    for x in data:\n",
    "        if x[0] == \"baseline\":\n",
    "            table += \"\\\\textbf{{{}}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{:.3f}}} & \\\\textbf{{{:.3f}}} \\\\\\\\\\n\".format(x[0], x[1], x[2], x[3], x[4], x[5], x[6])\n",
    "        else:\n",
    "            table += \"\\\\texttt{{{}}} & {:.3f} & {:.3f} & {:.3f} & {:.3f} & {:.3f} & {:.3f} \\\\\\\\\\n\".format(x[0], x[1], x[2], x[3], x[4], x[5], x[6])\n",
    "\n",
    "    table += \"\\\\bottomrule\\n\"\n",
    "    table += \"\\\\end{longtable}\\n\"\n",
    "    print(table)\n",
    "\n",
    "for exp_folder in [\n",
    "    \"../experiments/squad-pl-1k/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-1k-answer-only/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-5k/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-5k-answer-only/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-10k/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-10k-answer-only/herbert-base-cased\",\n",
    "    \"../experiments/squad-pl-50k/herbert-base-cased\"\n",
    "]:\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(exp_folder)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    rows = []\n",
    "    for exp in os.listdir(exp_folder):\n",
    "        f1 = []\n",
    "        em = []\n",
    "\n",
    "        f1_answer = []\n",
    "        em_answer = []\n",
    "\n",
    "        f1_no_answer = []\n",
    "        em_no_answer = []\n",
    "\n",
    "        for i in range(4):\n",
    "            if not os.path.exists(f\"{exp_folder}/{exp}/fold-{i}\"):\n",
    "                continue\n",
    "\n",
    "            with open(f\"{exp_folder}/{exp}/fold-{i}/eval_stats.json\", \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                f1.append(data[\"f1\"])\n",
    "                em.append(data[\"em\"])\n",
    "                f1_answer.append(data[\"f1_answer\"])\n",
    "                em_answer.append(data[\"em_answer\"])\n",
    "                f1_no_answer.append(data[\"f1_no_answer\"])\n",
    "                em_no_answer.append(data[\"em_no_answer\"])\n",
    "\n",
    "        #print(exp)\n",
    "        #print(\"all\", round(np.mean(f1), 4), round(np.mean(em), 4))\n",
    "        #print(\"answer only\", round(np.mean(f1_answer), 4), round(np.mean(em_answer), 4))\n",
    "        #print(\"no answer only\", round(np.mean(f1_no_answer), 4), round(np.mean(em_no_answer), 4))\n",
    "        #print(\"=\"*100)\n",
    "        rows.append((exp, np.mean(f1), np.mean(em), np.mean(f1_answer), np.mean(em_answer), np.mean(f1_no_answer), np.mean(em_no_answer)))\n",
    "    render_table(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
